[data & param & log & regime & monitor]
# data_collection/db_config.py
DATABASE = {
    'user': 'postgres',
    'password': '1234',
    'host': 'localhost',
    'port': 5432,
    'dbname': 'my_trading_db'
}

---

# data_collection/db_manager.py
from sqlalchemy import create_engine, text
from psycopg2.extras import execute_values
import pandas as pd
from data_collection.db_config import DATABASE

def insert_on_conflict(table, conn, keys, data_iter):
    raw_conn = conn.connection
    cur = raw_conn.cursor()
    values = list(data_iter)
    columns = ", ".join(keys)
    sql = f"INSERT INTO {table.name} ({columns}) VALUES %s ON CONFLICT (timestamp) DO NOTHING"
    execute_values(cur, sql, values)
    cur.close()

def insert_ohlcv_records(df: pd.DataFrame, table_name: str = 'ohlcv_data', conflict_action: str = "DO NOTHING", db_config: dict = None) -> None:
    if db_config is None:
        db_config = DATABASE
    engine = create_engine(
        f"postgresql://{db_config['user']}:{db_config['password']}@"
        f"{db_config['host']}:{db_config['port']}/{db_config['dbname']}"
    )
    create_table_sql = text(f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                timestamp TIMESTAMP NOT NULL,
                open DOUBLE PRECISION,
                high DOUBLE PRECISION,
                low DOUBLE PRECISION,
                close DOUBLE PRECISION,
                volume DOUBLE PRECISION,
                PRIMARY KEY (timestamp)
            );
            """)
    with engine.begin() as conn:
        conn.execute(create_table_sql)
    df = df.copy()
    df.reset_index(inplace=True)
    df.to_sql(
        table_name,
        engine,
        if_exists='append',
        index=False,
        method=insert_on_conflict
    )

def fetch_ohlcv_records(table_name: str = 'ohlcv_data', start_date: str = None, end_date: str = None, db_config: dict = None) -> pd.DataFrame:
    if db_config is None:
        db_config = DATABASE
    engine = create_engine(
        f"postgresql://{db_config['user']}:{db_config['password']}@"
        f"{db_config['host']}:{db_config['port']}/{db_config['dbname']}"
    )
    query = f"SELECT * FROM {table_name} WHERE 1=1"
    params = {}
    if start_date:
        query += " AND timestamp >= :start_date"
        params['start_date'] = start_date
    if end_date:
        query += " AND timestamp <= :end_date"
        params['end_date'] = end_date
    query += " ORDER BY timestamp"
    query = text(query)
    df = pd.read_sql(query, engine, params=params, parse_dates=['timestamp'])
    df.set_index('timestamp', inplace=True)
    return df

---

# data_collection/ohlcv_fetcher.py
import ccxt
import pandas as pd
from datetime import datetime
import time
from logs.logger_config import setup_logger

logger = setup_logger(__name__)

def fetch_historical_ohlcv_data(symbol: str, timeframe: str, start_date: str, 
                                limit_per_request: int = 1000, pause_sec: float = 1.0, 
                                exchange_id: str = 'binance', single_fetch: bool = False,
                                time_offset_ms: int = 1):
    """
    ccxt를 이용해 지정한 심볼, 타임프레임, 시작일로부터 OHLCV 데이터를 수집합니다.
    만약 single_fetch=True이면, 한 번의 요청만 수행합니다.
    
    반환된 DataFrame은 'open', 'high', 'low', 'close', 'volume' 컬럼을 가지며, 
    인덱스는 timestamp입니다.
    
    [time_offset_ms 설명]
    → 마지막으로 수집한 타임스탬프에 time_offset_ms(밀리초 단위)를 더하여,
       중복된 데이터 수집을 방지하기 위해 사용됩니다.
    """
    try:
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class({
            'enableRateLimit': True,
        })
        exchange.load_markets()
    except Exception as e:
        logger.error(f"Exchange '{exchange_id}' 초기화 에러: {e}")
        return pd.DataFrame()

    try:
        since = exchange.parse8601(datetime.strptime(start_date, "%Y-%m-%d").isoformat())
    except Exception as e:
        logger.error(f"start_date ({start_date}) 파싱 에러: {e}")
        return pd.DataFrame()

    ohlcv_list = []
    while True:
        try:
            ohlcvs = exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=limit_per_request)
        except Exception as e:
            logger.error(f"{symbol}의 {timeframe} 데이터 수집 에러: {e}")
            break

        if not ohlcvs:
            break

        ohlcv_list.extend(ohlcvs)
        
        # single_fetch 옵션이 True이면 한 번의 요청 후 종료
        if single_fetch:
            break

        last_timestamp = ohlcvs[-1][0]
        since = last_timestamp + time_offset_ms  # 중복 방지를 위해 offset 적용

        # 현재 시간보다 과거 데이터가 모두 수집되었으면 종료
        if last_timestamp >= exchange.milliseconds():
            break

        time.sleep(pause_sec)

    if ohlcv_list:
        df = pd.DataFrame(ohlcv_list, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        return df
    else:
        return pd.DataFrame()
    
def fetch_latest_ohlcv_data(symbol: str, timeframe: str, limit: int = 500, exchange_id: str = 'binance'):
    try:
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class({
            'enableRateLimit': True,
        })
        exchange.load_markets()
    except Exception as e:
        logger.error(f"Exchange '{exchange_id}' 초기화 에러: {e}")
        return pd.DataFrame()
    
    try:
        ohlcvs = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
    except Exception as e:
        logger.error(f"{symbol}의 {timeframe} 최신 데이터 수집 에러: {e}")
        return pd.DataFrame()
    
    if ohlcvs:
        df = pd.DataFrame(ohlcvs, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        return df
    else:
        return pd.DataFrame()
    
def get_top_market_cap_symbols(exchange_id: str = 'binance', quote_currency: str = 'USDT', 
                               required_start_date: str = "2018-01-01", count: int = 5, 
                               pause_sec: float = 1.0):
    try:
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class({
            'enableRateLimit': True,
        })
        markets = exchange.load_markets()
    except Exception as e:
        logger.error(f"{exchange_id}에서 마켓 로드 에러: {e}")
        return []

    usdt_symbols = [symbol for symbol in markets if symbol.endswith('/' + quote_currency)]
    
    try:
        tickers = exchange.fetch_tickers()
    except Exception as e:
        logger.error(f"티커 수집 에러: {e}")
        tickers = {}

    symbol_volumes = []
    for symbol in usdt_symbols:
        ticker = tickers.get(symbol, {})
        volume = ticker.get('quoteVolume', 0)
        symbol_volumes.append((symbol, volume))
    
    symbol_volumes.sort(key=lambda x: x[1] if x[1] is not None else 0, reverse=True)
    
    valid_symbols = []
    for symbol, volume in symbol_volumes:
        logger.info(f"심볼 {symbol}의 데이터 가용성 확인 중 (시작일: {required_start_date})...")
        df = fetch_historical_ohlcv_data(symbol, '1d', required_start_date, 
                                         limit_per_request=1, pause_sec=pause_sec, 
                                         exchange_id=exchange_id, single_fetch=True)
        if df.empty:
            logger.info(f"  → {symbol}은(는) {required_start_date} 이후 데이터만 존재하거나 데이터가 없음. 스킵합니다.")
            continue
        first_timestamp = df.index.min()
        if first_timestamp > pd.to_datetime(required_start_date):
            logger.info(f"  → {symbol}은(는) {required_start_date} 이후 상장됨 (최초 데이터: {first_timestamp}). 스킵합니다.")
            continue
        valid_symbols.append(symbol)
        if len(valid_symbols) >= count:
            break

    if len(valid_symbols) < count:
        logger.warning(f"경고: {required_start_date} 이전 데이터가 있는 유효 심볼이 {len(valid_symbols)}개 밖에 없습니다.")
    return valid_symbols

---

# data_collection/ohlcv_pipeline.py
import time
from typing import List, Optional
from logs.logger_config import setup_logger
from data_collection.ohlcv_fetcher import fetch_historical_ohlcv_data, fetch_latest_ohlcv_data
from data_collection.db_manager import insert_ohlcv_records

logger = setup_logger(__name__)

def collect_and_store_ohlcv_data(
    symbols: List[str],
    timeframes: List[str],
    use_historical: bool = True,
    start_date: Optional[str] = '2018-01-01 00:00:00',
    limit_per_request: int = 1000,
    latest_limit: int = 500,
    pause_sec: float = 1.0,
    table_name_format: str = "ohlcv_{symbol}_{timeframe}",
    exchange_id: str = 'binance',
    time_offset_ms: int = 1
) -> None:
    for symbol in symbols:
        for tf in timeframes:
            logger.info(f"[*] Fetching {symbol} - {tf} data...")
            if use_historical:
                if not start_date:
                    raise ValueError("start_date는 과거 데이터 수집 시 반드시 필요합니다.")
                df = fetch_historical_ohlcv_data(
                    symbol=symbol,
                    timeframe=tf,
                    start_date=start_date,
                    limit_per_request=limit_per_request,
                    pause_sec=pause_sec,
                    exchange_id=exchange_id,
                    single_fetch=False,
                    time_offset_ms=time_offset_ms
                )
            else:
                df = fetch_latest_ohlcv_data(
                    symbol=symbol,
                    timeframe=tf,
                    limit=latest_limit,
                    exchange_id=exchange_id
                )
            table_name = table_name_format.format(symbol=symbol.replace('/', '').lower(), timeframe=tf)
            logger.info(f"    -> Total Rows Fetched: {len(df)}")
            insert_ohlcv_records(df, table_name=table_name)
            logger.info(f"    -> Saved to table: {table_name}")
            time.sleep(pause_sec)

---

# dynamic_parameters/dynamic_param_manager.py
from logs.logger_config import setup_logger

class DynamicParamManager:
    def __init__(self):
        self.default_params = {
            "sma_period": 200,
            "atr_period": 14,
            "atr_multiplier": 2.07,
            "dynamic_sl_adjustment": 1.18,
            "profit_ratio": 0.098,
            "use_trailing_stop": True,
            "trailing_percent": 0.045,
            "partial_exit_ratio": 0.5,
            "partial_profit_ratio": 0.03,
            "final_profit_ratio": 0.06,
            "risk_per_trade": 0.0162,
            "total_splits": 3,
            "allocation_mode": "equal",
            "scale_in_threshold": 0.0153,
            "hmm_confidence_threshold": 0.8,
            "liquidity_info": "high",
            "volatility_multiplier": 1.0,  # 신규 파라미터: 변동성에 따른 리스크 조정
            "use_candle_pattern": True   # 신규 파라미터: 캔들 패턴 활용 여부
        }
        self.logger = setup_logger(__name__)
        self.logger.info("DynamicParamManager 초기화 완료 (레짐 기반 전략 적용).")

    def get_default_params(self):
        return self.default_params.copy()
    
    def update_dynamic_params(self, market_data):
        dynamic_params = self.get_default_params()
        volatility = market_data.get("volatility", 0.0)
        
        if volatility > 0.05:
            dynamic_params["atr_multiplier"] *= 1.1
            dynamic_params["volatility_multiplier"] = 1.2
        else:
            dynamic_params["atr_multiplier"] *= 0.9
            dynamic_params["volatility_multiplier"] = 1.0
        
        self.logger.info(f"Market data: {market_data}")
        self.logger.info(f"Updated dynamic parameters: {dynamic_params}")
        
        return dynamic_params

---

# logs/logger_config.py
import logging
import os

def setup_logger(module_name: str) -> logging.Logger:
    # logs 디렉토리가 없으면 생성
    if not os.path.exists('logs'):
        os.makedirs('logs')
    logger = logging.getLogger(module_name)
    logger.setLevel(logging.INFO)
    # 이미 핸들러가 있으면 그대로 반환
    if logger.handlers:
        return logger
    # 파일 핸들러: 파일명에 모듈명을 포함, 인코딩을 utf-8로 설정
    file_handler = logging.FileHandler(f"logs/{module_name}.log", encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('[%(asctime)s] %(levelname)s:%(name)s:%(funcName)s: %(message)s')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    # 콘솔 핸들러도 추가 (인코딩은 시스템에 따라 자동 처리됨)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    return logger

---

# markets_analysis/hmm_model.py
import numpy as np
import pandas as pd
from hmmlearn.hmm import GaussianHMM
from logs.logger_config import setup_logger

class MarketRegimeHMM:
    def __init__(self, n_components=3, covariance_type='full', n_iter=1000, random_state=42):
        self.n_components = n_components
        self.covariance_type = covariance_type
        self.n_iter = n_iter
        self.random_state = random_state
        self.model = GaussianHMM(n_components=self.n_components,
                                 covariance_type=self.covariance_type,
                                 n_iter=self.n_iter,
                                 random_state=self.random_state)
        # setup_logger를 통해 로거를 설정 (모듈명과 함수명 등이 로그에 포함됨)
        self.logger = setup_logger(__name__)
        self.trained = False

    def train(self, historical_data: pd.DataFrame, feature_columns: list = None):
        if historical_data.empty:
            self.logger.error("Historical data is empty. Training aborted.")
            raise ValueError("Historical data is empty.")
        if feature_columns is None:
            feature_columns = historical_data.columns.tolist()
        
        X = historical_data[feature_columns].values
        self.logger.info(f"Training HMM model with {X.shape[0]} samples and {X.shape[1]} features.")
        self.model.fit(X)
        self.trained = True
        self.logger.info("HMM training completed.")

    def predict(self, data: pd.DataFrame, feature_columns: list = None):
        if not self.trained:
            self.logger.error("Model is not trained. Prediction aborted.")
            raise ValueError("Model is not trained.")
        if data.empty:
            self.logger.error("Input data is empty. Prediction aborted.")
            raise ValueError("Input data is empty.")
        if feature_columns is None:
            feature_columns = data.columns.tolist()
        
        X = data[feature_columns].values
        predicted_states = self.model.predict(X)
        self.logger.info(f"Predicted states for {X.shape[0]} samples.")
        return predicted_states

    def update(self, new_data: pd.DataFrame, feature_columns: list = None):
        self.logger.info("Updating HMM model with new data.")
        if feature_columns is None:
            feature_columns = new_data.columns.tolist()
        X_new = new_data[feature_columns].values
        self.model.fit(X_new)
        self.logger.info("HMM model update completed.")

---

# markets_analysis/regime_filter.py
import numpy as np

def filter_by_confidence(hmm_model, data, feature_columns, threshold=0.8):
    """
    HMM 모델의 posterior 확률을 이용해 각 샘플의 예측 신뢰도를 평가합니다.
    
    :param hmm_model: MarketRegimeHMM 객체
    :param data: 예측에 사용할 pandas DataFrame
    :param feature_columns: 예측에 사용할 피처 컬럼 리스트 (예: ["returns", "volatility"])
    :param threshold: 신뢰도 임계치 (0.0 ~ 1.0)
    :return: numpy array (각 샘플이 threshold 이상이면 True, 아니면 False)
    """
    X = data[feature_columns].values
    # score_samples()를 사용해 각 샘플의 posterior 확률 분포를 구합니다.
    logprob, posteriors = hmm_model.model.score_samples(X)
    max_probs = posteriors.max(axis=1)
    return max_probs >= threshold

def adjust_regime(prediction, technical_indicators):
    """
    HMM 예측 결과와 보조 기술적 지표를 바탕으로 최종 시장 레짐을 조정합니다.
    
    :param prediction: HMM 예측 결과 (예: 정수형 상태값)
    :param technical_indicators: dict, 보조 지표 분석 결과 (예: {"trend": "bullish"})
    :return: 최종 조정된 시장 레짐 (문자열)
    """
    # HMM의 상태를 미리 정의된 매핑으로 변환합니다.
    state_mapping = {0: "bullish", 1: "bearish", 2: "sideways"}
    hmm_regime = state_mapping.get(prediction, "unknown") if isinstance(prediction, int) else prediction
    
    # 보조 지표에서 분석한 추세(trend) 값을 가져옵니다.
    tech_trend = technical_indicators.get("trend", None)
    
    # 간단한 조정 로직:
    # 보조 지표가 유효한 경우, 그 값을 우선적으로 사용합니다.
    if tech_trend in ["bullish", "bearish", "sideways"]:
        return tech_trend
    else:
        return hmm_regime
    
def get_regime_intervals(regime_series):
    """
    regime_series: pandas Series, 인덱스는 날짜, 값은 레짐 (예: bullish, bearish, sideways)
    반환: 각 레짐별 (레짐, 시작일, 종료일) 리스트
    """
    intervals = []
    if regime_series.empty:
        return intervals
    current_regime = regime_series.iloc[0]
    start_date = regime_series.index[0]
    for dt, regime in regime_series.iteritems():
        if regime != current_regime:
            end_date = dt
            intervals.append((current_regime, start_date, end_date))
            current_regime = regime
            start_date = dt
    intervals.append((current_regime, start_date, regime_series.index[-1]))
    return intervals

---

# monitoring/real_time_monitor.py
from logs.logger_config import setup_logger

class RealTimeMonitor:
    def __init__(self):
        self.logger = setup_logger(__name__)

    def monitor_trade_activity(self, positions, current_market_price):
        """
        보유 포지션, 체결 내역, 슬리피지 및 거래 비용을 모니터링하여 이상 징후 발생 시 알람.
        """
        for pos in positions:
            for exec_record in pos.executions:
                if not exec_record.get("closed", False):
                    entry_price = exec_record.get("entry_price")
                    if entry_price is None:
                        continue
                    price_change = abs(current_market_price - entry_price) / entry_price
                    if price_change > 0.1:  # 예: 10% 이상 변동 시 경고
                        self.logger.warning(f"RealTimeMonitor: Position {pos.position_id} has moved by {price_change*100:.2f}% from entry price.")

    def send_alert(self, message):
        # 이메일, SMS, 슬랙 등 연동 가능 (여기서는 로그 기록으로 대체)
        self.logger.info(f"ALERT: {message}")
