[data/ohlcv/ohlcv_aggregator.py]
# data/ohlcv/ohlcv_aggregator.py

import pandas as pd
from ta.trend import SMAIndicator  # 기술적 지표 중 단순 이동평균(SMA)을 계산하기 위한 라이브러리
from logs.logger_config import setup_logger  # 로깅 설정을 위한 모듈

# 전역 변수: 로깅 설정 객체
# 현재 파일의 이름을 기반으로 로깅을 설정하여 디버그 및 에러 로그 기록에 활용됩니다.
logger = setup_logger(__name__)

def aggregate_to_weekly(
    df: pd.DataFrame,
    compute_indicators: bool = True,
    resample_rule: str = "W-MON",
    label: str = "left",
    closed: str = "left",
    timezone: str = None,
    sma_window: int = 5
) -> pd.DataFrame:
    """
    OHLCV 데이터를 주간 단위로 집계하고, 선택적으로 기술적 지표를 계산합니다.
    인덱스의 타임존 조정도 가능하도록 합니다.
    
    Parameters:
        df (pd.DataFrame): datetime 인덱스를 가진 OHLCV 데이터. (open, high, low, close, volume 컬럼 포함)
        compute_indicators (bool): 추가 지표(주간 SMA, 모멘텀, 변동성)를 계산할지 여부.
        resample_rule (str): pandas의 재샘플링 규칙 (기본값 "W-MON": 월요일 기준 주간).
        label (str): 재샘플링 결과의 인덱스 라벨 위치 (기본 "left").
        closed (str): 구간의 닫힌 쪽 지정 (기본 "left").
        timezone (str): 인덱스의 타임존 변환 옵션 (예: "UTC", "Asia/Seoul").
        sma_window (int): 주간 단순 이동평균(SMA) 계산 시 윈도우 크기 (기본 5).
    
    Returns:
        pd.DataFrame: 주간 단위로 집계된 데이터프레임.
                      기본 컬럼: open, weekly_high, weekly_low, close, volume.
                      compute_indicators가 True이면 weekly_sma, weekly_momentum, weekly_volatility 컬럼 추가.
    """
    
    # 필수 컬럼들 (OHLCV 데이터) 존재 여부 확인
    required_columns = {"open", "high", "low", "close", "volume"}
    missing = required_columns - set(df.columns)
    if missing:
        # 필수 컬럼이 누락된 경우 에러 로그 기록 후 빈 DataFrame 반환
        logger.error(f"Input DataFrame is missing required columns: {missing}", exc_info=True)
        return pd.DataFrame()

    # 인덱스가 datetime 형식인지 확인 후 변환
    if not pd.api.types.is_datetime64_any_dtype(df.index):
        try:
            df.index = pd.to_datetime(df.index)
        except Exception as e:
            logger.error(f"Failed to convert index to datetime: {e}", exc_info=True)
            return pd.DataFrame()

    if df.empty:
        logger.error("Input DataFrame for aggregation is empty.", exc_info=True)
        return df

    try:
        if timezone:
            # 타임존이 지정된 경우: 인덱스가 naive이면 UTC로 로컬라이즈 후 지정된 타임존으로 변환
            if df.index.tz is None:
                df = df.tz_localize('UTC')
            df = df.tz_convert(timezone)
    except Exception as e:
        logger.error(f"Timezone conversion error: {e}", exc_info=True)

    try:
        # pandas의 resample 메소드를 이용하여 주간 단위로 OHLCV 데이터를 집계
        weekly = df.resample(rule=resample_rule, label=label, closed=closed).agg({
            'open': 'first',    # 해당 주의 첫 번째 가격을 open으로 사용
            'high': 'max',      # 주간 최고가
            'low': 'min',       # 주간 최저가
            'close': 'last',    # 해당 주의 마지막 가격을 close로 사용
            'volume': 'sum'     # 거래량은 주간 합계
        })
    except Exception as e:
        logger.error(f"Resampling error: {e}", exc_info=True)
        return pd.DataFrame()

    if weekly.empty:
        logger.error("Aggregated weekly DataFrame is empty after resampling.", exc_info=True)
        return weekly

    # 컬럼 이름 변경: 전략 개발 시 명확하게 식별할 수 있도록 high, low 컬럼을 주간 데이터로 재명명
    weekly.rename(columns={'high': 'weekly_high', 'low': 'weekly_low'}, inplace=True)

    if compute_indicators:
        try:
            # 주간 SMA 계산: SMAIndicator를 사용하여 close 가격의 단순 이동평균을 계산합니다.
            sma_indicator = SMAIndicator(close=weekly['close'], window=sma_window, fillna=True)
            weekly['weekly_sma'] = sma_indicator.sma_indicator()
            
            # 주간 모멘텀 계산: 주간 close 가격의 전 주 대비 백분율 변화
            weekly['weekly_momentum'] = weekly['close'].pct_change() * 100
            
            # 주간 변동성 계산: (주간 최고가 - 주간 최저가) / 주간 최저가,
            # 만약 주간 최저가가 0이면 0으로 설정하여 division by zero 방지
            weekly['weekly_volatility'] = weekly.apply(
                lambda row: (row['weekly_high'] - row['weekly_low']) / row['weekly_low']
                if row['weekly_low'] != 0 else 0.0, axis=1)
        except Exception as e:
            logger.error(f"Error computing weekly indicators: {e}", exc_info=True)
            
    # 최종 집계된 주간 데이터프레임 반환
    return weekly

[data/ohlcv/ohlcv_fetcher.py]
# data/ohlcv/ohlcv_fetcher.py

import ccxt  # 암호화폐 거래소 API 연동을 위한 라이브러리
import pandas as pd
from datetime import datetime
import time  # 시간 지연을 위한 모듈
from logs.logger_config import setup_logger  # 로깅 설정 모듈
from functools import lru_cache  # 함수 결과 캐싱을 위한 모듈

# 전역 변수: 로깅 설정 객체
logger = setup_logger(__name__)

@lru_cache(maxsize=32)  # 캐시를 통해 동일 파라미터 호출 시 중복 API 호출 방지
def fetch_historical_ohlcv_data(symbol: str, timeframe: str, start_date: str, 
                                limit_per_request: int = 1000, pause_sec: float = 1.0, 
                                exchange_id: str = 'binance', single_fetch: bool = False,
                                time_offset_ms: int = 1, max_retries: int = 3,
                                exchange_instance=None) -> pd.DataFrame:
    """
    지정된 심볼(symbol)과 시간 간격(timeframe)에 대해, start_date부터의 역사적 OHLCV 데이터를 ccxt를 통해 수집합니다.
    선택적으로 exchange_instance를 재사용하여 API 호출 횟수를 줄입니다.
    
    Parameters:
        symbol (str): 거래 심볼 (예: 'BTC/USDT').
        timeframe (str): 시간 간격 (예: '1d', '1h').
        start_date (str): 데이터 수집 시작일 ("YYYY-MM-DD" 또는 "YYYY-MM-DD HH:MM:SS").
        limit_per_request (int): 한 번 호출 시 가져올 데이터 개수 (기본값 1000).
        pause_sec (float): API 호출 간 대기 시간 (기본값 1.0초).
        exchange_id (str): 사용 거래소 ID (기본값 'binance').
        single_fetch (bool): 한 번의 호출만 수행할지 여부.
        time_offset_ms (int): 다음 호출 시 타임스탬프 오프셋 (밀리초 단위).
        max_retries (int): 최대 재시도 횟수 (기본값 3).
        exchange_instance: 재사용할 ccxt 거래소 인스턴스 (옵션).
    
    Returns:
        pd.DataFrame: OHLCV 데이터를 포함하는 DataFrame. 컬럼은 ['timestamp', 'open', 'high', 'low', 'close', 'volume'].
    """
    # exchange_instance가 제공되지 않은 경우, 새로운 ccxt 거래소 인스턴스 생성 및 마켓 로드
    if exchange_instance is None:
        try:
            exchange_class = getattr(ccxt, exchange_id)
            exchange = exchange_class({'enableRateLimit': True, 'timeout': 30000})
            logger.debug(f"{exchange_id}: Loading markets...")
            exchange.load_markets()  # 해당 거래소의 마켓 정보를 불러옴
            logger.debug(f"{exchange_id}: Markets loaded successfully.")
        except Exception as e:
            logger.error(f"Exchange '{exchange_id}' 초기화 에러: {e}", exc_info=True)
            return pd.DataFrame()
    else:
        exchange = exchange_instance

    try:
        # 시작일이 "YYYY-MM-DD" 형식이면 " 00:00:00"을 추가하여 완전한 datetime 문자열로 만듦
        if len(start_date.strip()) == 10:
            start_date += " 00:00:00"
        # 시작일을 ISO 포맷으로 변환한 후, ccxt의 parse8601를 이용하여 밀리초 단위 timestamp로 변환
        since = exchange.parse8601(datetime.strptime(start_date, "%Y-%m-%d %H:%M:%S").isoformat())
    except Exception as e:
        logger.error(f"start_date ({start_date}) 파싱 에러: {e}", exc_info=True)
        return pd.DataFrame()

    ohlcv_list = []  # 수집된 OHLCV 데이터를 저장할 리스트
    retry_count = 0  # 재시도 횟수 초기화
    while True:
        try:
            # 지정된 심볼, 시간 간격, 시작 시점(since), 요청당 데이터 제한을 기준으로 OHLCV 데이터 호출
            ohlcvs = exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=limit_per_request)
        except Exception as e:
            logger.error(f"{symbol}의 {timeframe} 데이터 수집 에러: {e}", exc_info=True)
            retry_count += 1
            if retry_count >= max_retries:
                logger.error(f"최대 재시도({max_retries}) 초과로 {symbol} {timeframe} 데이터 수집 중단")
                break
            time.sleep(pause_sec)
            continue

        if not ohlcvs:
            # 더 이상 데이터가 없으면 반복문 종료
            break

        ohlcv_list.extend(ohlcvs)
        
        if single_fetch:
            # 한 번의 호출만 필요한 경우 반복 종료
            break

        # 마지막 데이터의 타임스탬프를 확인하여, 다음 호출 시 시작점을 업데이트
        last_timestamp = ohlcvs[-1][0]
        since = last_timestamp + time_offset_ms

        # 만약 마지막 타임스탬프가 현재 시간(밀리초) 이상이면 더 이상 데이터를 요청하지 않음
        if last_timestamp >= exchange.milliseconds():
            break

        time.sleep(pause_sec)  # API rate limit 준수를 위한 대기

    if ohlcv_list:
        try:
            # 리스트를 DataFrame으로 변환하고, 컬럼명을 지정
            df = pd.DataFrame(ohlcv_list, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            # 타임스탬프 컬럼을 datetime 형식으로 변환 (밀리초 단위)
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            # 인덱스를 timestamp로 설정
            df.set_index('timestamp', inplace=True)
            return df.copy()  # 복사본 반환
        except Exception as e:
            logger.error(f"DataFrame 변환 에러: {e}", exc_info=True)
            return pd.DataFrame()
    else:
        logger.warning(f"{symbol} {timeframe}에 대한 데이터가 없습니다.")
        return pd.DataFrame()

@lru_cache(maxsize=32)
def fetch_latest_ohlcv_data(symbol: str, timeframe: str, limit: int = 500, exchange_id: str = 'binance') -> pd.DataFrame:
    """
    지정된 심볼(symbol)과 시간 간격(timeframe)에 대해 최신 OHLCV 데이터를 수집합니다.
    
    Parameters:
        symbol (str): 거래 심볼 (예: 'BTC/USDT').
        timeframe (str): 시간 간격 (예: '1d', '1h').
        limit (int): 가져올 데이터 개수 제한 (기본값 500).
        exchange_id (str): 사용 거래소 ID (기본값 'binance').
    
    Returns:
        pd.DataFrame: 최신 OHLCV 데이터를 포함하는 DataFrame.
    """
    try:
        # ccxt 거래소 인스턴스 생성 및 마켓 로드
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class({'enableRateLimit': True, 'timeout': 30000})
        exchange.load_markets()
    except Exception as e:
        logger.error(f"Exchange '{exchange_id}' 초기화 에러: {e}", exc_info=True)
        return pd.DataFrame()
    
    try:
        # 최신 데이터 호출 (limit 개수만큼)
        ohlcvs = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
    except Exception as e:
        logger.error(f"{symbol}의 {timeframe} 최신 데이터 수집 에러: {e}", exc_info=True)
        return pd.DataFrame()
    
    if ohlcvs:
        try:
            # 수집된 데이터를 DataFrame으로 변환 및 인덱스 설정
            df = pd.DataFrame(ohlcvs, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            return df.copy()
        except Exception as e:
            logger.error(f"DataFrame 변환 에러: {e}", exc_info=True)
            return pd.DataFrame()
    else:
        logger.warning(f"{symbol} {timeframe}에 대한 최신 데이터가 없습니다.")
        return pd.DataFrame()

def get_top_volume_symbols(exchange_id: str = 'binance', quote_currency: str = 'USDT', 
                           count: int = 5, pause_sec: float = 1.0) -> list:
    """
    Binance의 경우, 거래량(quoteVolume)을 시총 대용 지표로 사용하여 거래소 내 유효 심볼 중 상위 count개를 선택합니다.
    스테이블 코인은 제외하며, 각 심볼의 최초 데이터 제공일(온보딩 날짜)을 함께 반환합니다.
    
    Parameters:
        exchange_id (str): 사용 거래소 ID (기본 'binance').
        quote_currency (str): 기준 통화 (예: 'USDT').
        count (int): 반환할 심볼 개수 (기본 5).
        pause_sec (float): API 호출 사이의 대기 시간 (기본 1.0초).
    
    Returns:
        list: (symbol, first_available_date) 튜플의 리스트.
    """
    try:
        # ccxt 거래소 인스턴스 생성 및 마켓 정보 로드
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class({'enableRateLimit': True, 'timeout': 30000})
        logger.debug(f"{exchange_id}: Loading markets for top symbol retrieval...")
        markets = exchange.load_markets()
        logger.debug(f"{exchange_id}: Markets loaded, total symbols: {len(markets)}")
    except Exception as e:
        logger.error(f"{exchange_id}에서 마켓 로드 에러: {e}", exc_info=True)
        return []

    # USDT 마켓에 해당하는 심볼 필터링 (예: 'BTC/USDT')
    usdt_symbols = [symbol for symbol in markets if symbol.endswith('/' + quote_currency)]
    
    # 스테이블 코인 목록: 해당 코인들은 제외
    stable_coins = {
        "USDT", "BUSD", "USDC", "DAI", "TUSD", "PAX", "USDP", "GUSD", "MIM", "UST",
        "USDe",  # Ethena USD (synthetic dollar)
        "FDUSD",  # First Digital USD
        "PYUSD",  # PayPal USD
        "USD0",  # Usual USD
        "FRAX",  # Frax Finance Stablecoin
        "USDY",  # Ondo USD Yield
        "USDD",  # Tron-based stablecoin
        "EURS",  # Stasis Euro stablecoin
        "RLUSD",  # Ripple USD
        "GHO",  # Aave Stablecoin
        "crvUSD",  # Curve Finance Stablecoin
        "LUSD",  # Liquity USD (ETH-backed stablecoin)
        "XAU₮",  # Tether Gold (Gold-backed stablecoin)
        "PAXG",  # Paxos Gold
        "EUROC",  # Circle Euro Coin
    }
    
    # 스테이블 코인 제외: 심볼의 기본 통화가 stable_coins에 속하지 않는 경우만 필터링
    filtered_symbols = [symbol for symbol in usdt_symbols if symbol.split('/')[0] not in stable_coins]
    logger.debug(f"Filtered symbols (excluding stablecoins): {len(filtered_symbols)} out of {len(usdt_symbols)}")

    # 거래소가 Binance인 경우, 거래량을 기준으로 정렬하여 상위 심볼 선택
    if exchange_id == 'binance':
        try:
            tickers = exchange.fetch_tickers()
        except Exception as e:
            logger.error(f"Error fetching tickers from {exchange_id}: {e}", exc_info=True)
            tickers = {}
        symbol_volumes = []
        for symbol in filtered_symbols:
            ticker = tickers.get(symbol, {})
            vol = ticker.get('quoteVolume', 0)
            try:
                vol = float(vol)
            except Exception:
                vol = 0
            symbol_volumes.append((symbol, vol))
        # 거래량(quoteVolume) 기준 내림차순 정렬
        symbol_volumes.sort(key=lambda x: x[1], reverse=True)
        sorted_symbols = [item[0] for item in symbol_volumes]
    else:
        # Binance가 아닌 경우, marketCap 정보를 사용하여 정렬
        symbol_caps = []
        for symbol in filtered_symbols:
            market_info = markets.get(symbol, {})
            cap = market_info.get('info', {}).get('marketCap')
            if cap is None:
                cap = 0
            try:
                cap = float(cap)
            except Exception:
                cap = 0
            symbol_caps.append((symbol, cap))
        symbol_caps.sort(key=lambda x: x[1], reverse=True)
        sorted_symbols = [item[0] for item in symbol_caps]

    valid_symbols = []
    # 각 심볼에 대해 첫 데이터 제공일(온보딩 날짜)을 확인
    for symbol in sorted_symbols:
        # 시작 날짜를 "2018-01-01"로 고정하여 데이터 호출
        df = fetch_historical_ohlcv_data(symbol, '1d', "2018-01-01", 
                                         limit_per_request=1, pause_sec=pause_sec, 
                                         exchange_id=exchange_id, single_fetch=True,
                                         exchange_instance=exchange)
        if df.empty:
            # 데이터가 없으면 해당 심볼 건너뜀
            continue
        first_timestamp = df.index.min()
        first_date_str = first_timestamp.strftime("%Y-%m-%d %H:%M:%S")
        valid_symbols.append((symbol, first_date_str))
        if len(valid_symbols) >= count:
            # 원하는 개수만큼 수집되면 종료
            break

    if len(valid_symbols) < count:
        logger.warning(f"경고: 유효한 데이터가 있는 심볼이 {len(valid_symbols)}개 밖에 없습니다.")
    return valid_symbols

def get_latest_onboard_date(symbols: list, exchange_id: str = 'binance') -> str:
    """
    전달된 심볼 리스트(튜플 또는 단순 심볼 문자열)에 대해 각 심볼의 최초 데이터 제공일(온보딩 날짜)을 구하여,
    가장 늦은(최신) 날짜를 반환합니다.
    
    Parameters:
        symbols (list): 심볼 문자열 또는 (symbol, first_available_date) 튜플 리스트.
        exchange_id (str): 사용 거래소 ID (기본 'binance').
    
    Returns:
        str: 가장 늦은 온보딩 날짜를 "YYYY-MM-DD HH:MM:SS" 형식으로 반환.
    """
    onboard_dates = []
    try:
        for item in symbols:
            if isinstance(item, tuple):
                # 심볼이 튜플인 경우, 두 번째 요소에 첫 데이터 제공일이 포함되어 있음
                onboard_str = item[1]
            else:
                # 단순 심볼인 경우, fetch_historical_ohlcv_data를 호출하여 온보딩 날짜를 확인
                exchange_class = getattr(ccxt, exchange_id)
                exchange = exchange_class({'enableRateLimit': True, 'timeout': 30000})
                exchange.load_markets()
                df = fetch_historical_ohlcv_data(item, '1d', "2018-01-01", 
                                                 limit_per_request=1, single_fetch=True, 
                                                 exchange_instance=exchange)
                if df.empty:
                    onboard_str = "2018-01-01 00:00:00"
                else:
                    onboard_str = df.index.min().strftime("%Y-%m-%d %H:%M:%S")
            try:
                # 문자열을 datetime 객체로 변환하여 리스트에 저장
                dt = datetime.strptime(onboard_str, "%Y-%m-%d %H:%M:%S")
                onboard_dates.append(dt)
            except Exception:
                onboard_dates.append(datetime.strptime("2018-01-01 00:00:00", "%Y-%m-%d %H:%M:%S"))
        if onboard_dates:
            # 가장 최근 날짜를 선택하여 문자열로 반환
            latest_date = max(onboard_dates)
            return latest_date.strftime("%Y-%m-%d %H:%M:%S")
    except Exception as e:
        logger.error(f"Error in get_latest_onboard_date: {e}", exc_info=True)
    return "2018-01-01 00:00:00"

[data/ohlcv/ohlcv_pipeline.py]
# data/ohlcv/ohlcv_pipeline.py

import time  # API 호출 간 지연 시간 적용을 위한 모듈
import threading  # 멀티스레딩 및 동기화를 위한 모듈
from typing import List, Optional  # 타입 힌트를 위한 모듈
import concurrent.futures  # 스레드 풀을 사용한 병렬 처리 모듈

from logs.logger_config import setup_logger  # 로깅 설정 모듈
from data.ohlcv.ohlcv_fetcher import (
    fetch_historical_ohlcv_data,
    fetch_latest_ohlcv_data
)
from data.db.db_manager import insert_ohlcv_records  # 수집된 데이터를 데이터베이스에 저장하기 위한 함수

# 전역 변수: 로깅 설정 객체
logger = setup_logger(__name__)

# 전역 변수: API 호출 결과 캐싱을 위한 in-memory 캐시와 해당 접근을 위한 락
_cache_lock = threading.Lock()  # 멀티스레딩 환경에서 캐시 동시 접근 제어용 락
_ohlcv_cache: dict = {}         # 이미 호출한 OHLCV 데이터를 저장하여 중복 API 호출 방지

def collect_and_store_ohlcv_data(
    symbols: List[str],
    timeframes: List[str],
    use_historical: bool = True,
    start_date: Optional[str] = '2018-01-01 00:00:00',
    limit_per_request: int = 1000,
    latest_limit: int = 500,
    pause_sec: float = 1.0,
    table_name_format: str = "ohlcv_{symbol}_{timeframe}",
    exchange_id: str = 'binance',
    time_offset_ms: int = 1
) -> None:
    """
    지정된 심볼과 시간 간격에 대해 OHLCV 데이터를 수집하고 데이터베이스에 저장합니다.
    - use_historical가 True이면 과거 데이터를, False이면 최신 데이터만 수집합니다.
    - in-memory 캐시를 사용하여 중복 API 호출을 피하고, 동시 실행을 위해 스레드 풀을 사용합니다.
    
    Parameters:
        symbols (List[str]): 거래 심볼 리스트 (예: ['BTC/USDT', 'ETH/USDT']).
        timeframes (List[str]): 시간 간격 리스트 (예: ['1d', '1h']).
        use_historical (bool): 과거 데이터 수집 여부.
        start_date (Optional[str]): 과거 데이터 수집 시작일 (use_historical True 시 필수).
        limit_per_request (int): 과거 데이터 수집 시 요청당 데이터 제한.
        latest_limit (int): 최신 데이터 수집 시 요청 제한 개수.
        pause_sec (float): API 호출 간 대기 시간.
        table_name_format (str): 데이터 저장 시 테이블 이름 형식. {symbol}과 {timeframe}이 포맷팅됨.
        exchange_id (str): 사용 거래소 ID (기본 'binance').
        time_offset_ms (int): 데이터 수집 시 타임스탬프 오프셋 (밀리초 단위).
    
    Returns:
        None
    """
    
    # 내부 함수: 각 심볼과 시간 간격(timeframe) 조합에 대해 데이터를 처리 및 저장합니다.
    def process_symbol_tf(symbol: str, tf: str) -> None:
        # 캐시 키 구성: 파라미터 조합을 튜플로 묶어 고유 식별자 역할 수행
        key = (symbol, tf, use_historical, start_date, limit_per_request, latest_limit, exchange_id, time_offset_ms)
        with _cache_lock:
            # 캐시에서 이미 데이터가 존재하는지 확인
            if key in _ohlcv_cache:
                df = _ohlcv_cache[key]
                logger.debug(f"Cache hit for {symbol} {tf}")
            else:
                logger.debug(f"Cache miss for {symbol} {tf}, fetching data")
                # 과거 데이터를 수집하는 경우 반드시 start_date가 필요함
                if use_historical:
                    if not start_date:
                        raise ValueError("과거 데이터 수집 시 start_date가 필요합니다.")
                    df = fetch_historical_ohlcv_data(
                        symbol=symbol,
                        timeframe=tf,
                        start_date=start_date,
                        limit_per_request=limit_per_request,
                        pause_sec=pause_sec,
                        exchange_id=exchange_id,
                        single_fetch=False,
                        time_offset_ms=time_offset_ms
                    )
                else:
                    # 최신 데이터 수집
                    df = fetch_latest_ohlcv_data(
                        symbol=symbol,
                        timeframe=tf,
                        limit=latest_limit,
                        exchange_id=exchange_id
                    )
                # 수집한 데이터를 캐시에 저장하여 후속 호출 시 재사용
                _ohlcv_cache[key] = df
        
        if df.empty:
            logger.warning(f"[OHLCV PIPELINE] {symbol} - {tf} 데이터가 없습니다. 저장 건너뜁니다.")
            return
        
        # 테이블 이름 구성: 심볼의 슬래시 제거 및 소문자 변환, 시간 간격 포함
        table_name = table_name_format.format(symbol=symbol.replace('/', '').lower(), timeframe=tf)
        try:
            # 수집한 OHLCV 데이터를 데이터베이스에 저장하는 함수 호출
            insert_ohlcv_records(df, table_name=table_name)
            logger.debug(f"Data inserted for {symbol} {tf} into table {table_name}")
        except Exception as e:
            logger.error(f"[OHLCV PIPELINE] 데이터 저장 에러 ({table_name}): {e}", exc_info=True)
        time.sleep(pause_sec)  # API rate limit 준수를 위해 짧은 대기 시간 적용

    tasks = []  # 스레드풀에 제출할 작업들을 저장하는 리스트
    # 최대 10개의 스레드로 동시 실행 (병렬 처리)
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        for symbol in symbols:
            for tf in timeframes:
                # 각 심볼-시간간격 조합에 대해 process_symbol_tf 함수를 스레드풀에 제출
                tasks.append(executor.submit(process_symbol_tf, symbol, tf))
        # 모든 제출된 작업이 완료될 때까지 대기
        concurrent.futures.wait(tasks)
